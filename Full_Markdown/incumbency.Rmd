---
title: "Incumbency and Probiblistic Models"
author: "Samuel Thau"
date: "10/3/2020"
output:
  rmarkdown::html_document:
    theme: cerulean
    
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../Posts/") })    

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggplot2)
library(usmap)
library(janitor)
library(usmap)

# read in all data
nat_popvote_df <- read_csv("../Data/popvote_1948-2016.csv")
nat_poll_df    <- read_csv("../Data/pollavg_1968-2016.csv")

state_popvote_df <- read_csv("../Data/popvote_bystate_1948-2016.csv")
state_poll_df <- read_csv("../Data/pollavg_bystate_1968-2016.csv")

nat_econ <- read_csv("../Data/econ.csv")
state_rdi <- read_csv("../Data/state_rdi.csv")

# clean data
#build state df with econ, polls, and 
weeks <- 4
poll_df <- state_poll_df %>% filter(weeks_left >= weeks, weeks_left<25) %>% 
  select(year, state, party, candidate_name, avg_poll) %>% 
  group_by(year, state, candidate_name, party) %>%
  summarize(avg_poll = mean(avg_poll))

#build economic df at state level from rdi and national gdp
econ_df <- state_rdi[,1:2]
colnames(econ_df) <- c("state","rdi_q2")
econ_df$rdi_q2 <- as.numeric(econ_df$rdi_q2)

for(i in seq(from = 18, to = 290, by = 16)){
  temp <- state_rdi[,c(1,i)]
  colnames(temp) <- c("state","rdi_q2")
  temp$rdi_q2 <- as.numeric(temp$rdi_q2)
  econ_df <- rbind(econ_df, temp)
}

#add years and national gdp growth
year_list <- seq(from = 1948, to = 2020, by=4)
year_append <- rep(year_list[1],51)
nat_econ_sub <- nat_econ %>% filter(year %in% year_list, quarter == 2) %>% 
  select(year, GDP_growth_qt)
gdp_append <- as.numeric(rep(nat_econ_sub[1,2],51))

for(i in seq(from = 2, to=length(year_list), by =1)){
  new_year = rep(year_list[i], 51)
  new_gdp = as.numeric(rep(nat_econ_sub[i,2], 51))
  year_append = append(year_append, new_year)
  gdp_append = append(gdp_append, new_gdp)
}

#append year and national gdp to the econ df
econ_df$year <- year_append
econ_df$gdp <- gdp_append


## Merge datasets and clean
inc_data <- nat_popvote_df %>% select("year","party","winner", "incumbent","incumbent_party")

reg_df <- poll_df %>% left_join(econ_df, by=c("state"="state","year"="year")) %>% 
  left_join(state_popvote_df, by= c("state"="state", "year"="year")) %>%
  left_join(inc_data, 
            by  = c("year"="year","party" = "party" ))

reg_df$period <- ifelse(reg_df$year %in% 1952:1972, "1952-1976",
                        ifelse(reg_df$year %in% 1972:1992, "1972-1992", "1996-2020"))

reg_df <- reg_df %>% mutate("d_pv"=100*D/total) %>% mutate("r_pv"=100*R/total)
reg_df <- reg_df %>% 
  mutate(inc_party = case_when((party=="democrat" & incumbent_party==TRUE) ~ "democrat", 
                               (party=="democrat" & incumbent_party==FALSE) ~ "republican",
                               (party=="republican" & incumbent_party==TRUE) ~ "republican",
                               (party=="republican" & incumbent_party==FALSE) ~ "democrat")) %>%
  mutate(chl_party = case_when((party=="democrat" & incumbent_party==FALSE) ~ "democrat", 
                               (party=="democrat" & incumbent_party==TRUE) ~ "republican",
                               (party=="republican" & incumbent_party==FALSE) ~ "republican",
                               (party=="republican" & incumbent_party==TRUE) ~ "democrat"))

reg_df <- reg_df %>% 
  mutate(inc_pv = case_when((inc_party=="republican") ~ R_pv2p, 
                            (inc_party=="democrat") ~ D_pv2p)) %>% 
  mutate(chl_pv = case_when(chl_party == "democrat" ~ D_pv2p, 
                            chl_party == "republican" ~ R_pv2p))

reg_df <- reg_df %>% mutate(incumbent_win = case_when(inc_party == "republican" & r_pv > d_pv ~ 1,
                                                      inc_party == "republican" & r_pv < d_pv ~ 0, 
                                                      inc_party == "democrat" & r_pv < d_pv ~ 1,
                                                      inc_party == "democrat" & r_pv > d_pv ~ 0))

reg_df <- na.omit(reg_df)


## modified polls plus as comparison
inc_plus_lm <- lm(inc_pv ~ rdi_q2 + gdp + state + avg_poll + period, data = reg_df %>% filter(year < 2020, incumbent_party == TRUE))
summary(inc_plus_lm)

chl_plus_lm <- lm(chl_pv ~ rdi_q2 + gdp + state + avg_poll + period, data = reg_df %>% filter(year < 2020, incumbent_party == FALSE))
summary(chl_plus_lm)

mean(abs(inc_plus_lm$residuals))
mean(abs(chl_plus_lm$residuals))

## logit regression for incumbent vote share
inc_log <- glm(incumbent_win ~ rdi_q2 + gdp + state + avg_poll + period, 
               data = reg_df %>% filter(year < 2020, incumbent_party == TRUE), family=binomial)
summary(inc_log)

## out of sample comparisons
# run out of sample fit to see how often states are called correctly
year_list <- seq(from = 1972, to = 2016, by = 4)
state_list <- unique(reg_df$state)


check_out1 <- function(year, state){
  #true vote shares
  true_inc <- reg_df$inc_pv[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party == TRUE]
  true_chl <- reg_df$chl_pv[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party  == FALSE]
  
  if (length(true_inc)>0){
    
    #dataframes excluding the row (incumbency is backwards as everything is negated)
    inc_df <- reg_df %>% filter(!(incumbent_party == FALSE & year == year & state == state))
    chl_df <- reg_df %>% filter(!(incumbent_party == TRUE & year == year & state == state))
    
    #prediction dataframes
    inc_p <- reg_df[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party == TRUE,]
    chl_p <- reg_df[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party == FALSE,]
    
    ##plus model out-of-sample prediction
    mod_plus_inc_ <- lm(inc_pv ~ avg_poll + rdi_q2 + gdp + state, data = inc_df)
    mod_plus_chl_ <- lm(chl_pv ~ avg_poll + rdi_q2 + gdp + state, data = chl_df)
    pred_plus_inc <- predict(mod_plus_inc_, inc_p)
    pred_plus_chl <- predict(mod_plus_chl_, chl_p)
    
    ## logit regression for the incumbent
    inc_log <- glm(incumbent_win ~ rdi_q2 + gdp + state + avg_poll + period, data = inc_df, family=binomial)    
    pred_inc_log <- 100*predict(inc_log, inc_p, type = "response")
    
    c(year, state,
      plus_margin_error = (pred_plus_inc-pred_plus_chl) - (true_inc-true_chl),
      plus_winner_correct = (pred_plus_inc > pred_plus_chl) == (true_inc > true_chl),
      log_winner_correct = (pred_inc_log > 50) == inc_p$incumbent_win
    )
  }else{
    c(NA, NA, NA, NA, NA)
  }
}

outsamp_dflist <- sapply(year_list, function(year){sapply(state_list, function(state) check_out1(year,state))})

outsamp_df <- cbind("year", "state","plus_margin_error",
                    "plus_winner_correct","log_winner_correct")

for(j in seq(from = 1, to = 12, by =1)){
  for(i in seq(from = 1, to = 251, by = 5)){
    start <- i
    stop <- i+4
    temp <- outsamp_dflist[start:stop, j]
    outsamp_df <- rbind(outsamp_df, temp)
  }
}

outsamp_df <- as.data.frame(outsamp_df)  
rownames(outsamp_df) <- NULL
outsamp_df <- outsamp_df %>% row_to_names(row_number=1)
outsamp_df_clean <- na.omit(outsamp_df)

plus_w <- length(outsamp_df_clean$plus_winner_correct[outsamp_df_clean$plus_winner_correct== TRUE])/length(outsamp_df_clean$plus_winner_correct)
log_w <- length(outsamp_df_clean$log_winner_correct[outsamp_df_clean$log_winner_correct== TRUE])/length(outsamp_df_clean$log_winner_correct)

outsamp_df_clean <- outsamp_df_clean %>% mutate(plus_idx = case_when(plus_winner_correct == TRUE ~ 1, plus_winner_correct == FALSE ~ 0)) %>%
  mutate(log_idx = case_when(log_winner_correct == TRUE  ~ 1, log_winner_correct == FALSE  ~ 0))

ln_log_cor <- cor(outsamp_df_clean$plus_idx, outsamp_df_clean$log_idx)


## ensemble model check
check_out2 <- function(year, state){
  #true vote shares
  true_inc <- reg_df$inc_pv[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party == TRUE]

  if (length(true_inc)>0){
    
    #dataframes excluding the row (incumbency is backwards as everything is negated)
    inc_df <- reg_df %>% filter(!(incumbent_party == FALSE & year == year & state == state))

    #prediction dataframes
    inc_p <- reg_df[reg_df$year == year & reg_df$state == state & reg_df$incumbent_party == TRUE,]

    ##plus model out-of-sample prediction
    mod_plus_inc_ <- lm(inc_pv ~ avg_poll + rdi_q2 + gdp + state, data = inc_df)
    pred_plus_inc <- predict(mod_plus_inc_, inc_p)

    ## logit regression for the incumbent
    inc_log <- glm(incumbent_win ~ rdi_q2 + gdp + state + avg_poll + period, data = inc_df, family=binomial)    
    pred_inc_log <- 100*predict(inc_log, inc_p, type = "response")
    
    ## ensemble model out of sample check
    pred_ens <- plus_w/(plus_w+log_w)*pred_plus_inc + log_w/(plus_w+log_w)*pred_inc_log
    
    c(year, state,
      plus_winner_correct = (pred_plus_inc > 50) == inc_p$incumbent_win,
      log_winner_correct = (pred_inc_log > 50) == inc_p$incumbent_win,
      ensemble_winner_correct = (pred_ens > 50) == inc_p$incumbent_win
    )
  }else{
    c(NA, NA, NA, NA, NA)
  }
}

outsamp_ens_list <- sapply(year_list, function(year){sapply(state_list, function(state) check_out2(year,state))})

outsamp_ens_df <- cbind("year", "state",
                    "plus_winner_correct","log_winner_correct","ens_winner_correct")

for(j in seq(from = 1, to = 12, by =1)){
  for(i in seq(from = 1, to = 251, by = 5)){
    start <- i
    stop <- i+4
    temp <- outsamp_dflist[start:stop, j]
    outsamp_ens_df <- rbind(outsamp_ens_df, temp)
  }
}

outsamp_ens_df <- as.data.frame(outsamp_ens_df)  
rownames(outsamp_ens_df) <- NULL
outsamp_ens_df <- outsamp_ens_df %>% row_to_names(row_number=1)
outsamp_ens <- na.omit(outsamp_ens_df)

ens_w <- length(outsamp_ens$ens_winner_correct[outsamp_ens$ens_winner_correct== TRUE])/length(outsamp_ens$ens_winner_correct)

```

## Introduction
This week, I'm going to be covering a number of different topics: first, I'll focus on the issue of incumbency and how it relates to models I have built; then, I'll touch on logistic regressions as a way to build more effective forecasts for the presidential elections. I will close with a brief discussion about what the models suggest to me for the next steps.

## Incumbency
To say Donald Trump's re-election campaign has been a unique one is an understatement. From filing the campaign paperwork with the Federal Election Commission on the day of his inauguration[^1], to leveraging the power of the federal government, to the particular messaging approach, there are many factors that make it hard to figure out how to model this election. All three points that I just alluded to deal with the idea of incumbency. 

A commonly cited fact in forecasting presidential elections is that incumbent presidents have an advantage: eight of the eleven incumbents who have run for re-election since World War II have won their races. There are many explanations for why, and we should think critically about if possible reasons apply to President Trump's re-election campaign.

One explanation is money: because Trump was able to officially begin his campaign on the day of his inauguration, and avoided a costly primary, meaning that he entered the final stretch of the campaign with [187 million dollars more](https://www.nytimes.com/2020/04/21/us/politics/biden-2020-fundraising.html) than Joe Biden. However, there is also evidence that this will not play a major role in deciding the election, as the Trump campaign is [having a cash crunch,](https://www.nytimes.com/2020/09/07/us/politics/trump-election-campaign-fundraising.html) having spent huge amount on legal fees, travel expenses for aids, and a number of highly paid consultants. To that end, it may be that because Trump does not have a cash advantage, he may have less of an advantage. 

Another possible angle is that because Trump currently has the might of the federal government behind him, he can use that to his advantage in the run up to the election. This theory is quantified by [Kriner and Reeves (2012)](https://www-cambridge-org.ezp-prod1.hul.harvard.edu/core/services/aop-cambridge-core/content/view/D7E15E901EA52BF92E5986626766224F/S0003055412000159a.pdf/div-class-title-the-influence-of-federal-spending-on-presidential-elections-div.pdf), which links county level federal grants to wins by incumbents. As we saw [last week](polls.html), the CARES Act greatly increased people's real disposable incomes in the second quarter of 2020[^2], which in the fundamentals model leads to a landslide victory for Trump[^3]. However, this relationship may not be quite that straightforward: [the majority of Americans do not approve](https://projects.fivethirtyeight.com/coronavirus-polls/) of how Trump has handled the COVID crisis, meaning they may not respond in the way we think to increased income as they only needed it because of the dire state the country is in.

A third factor to consider is campaign messaging (which we will take a longer look at after the election happens): Trump's messaging has not been consistent with what most incumbent campaigns look like[^4]. He continues to campaign as if he is the outsider, using messaging that was effective in 2016. A number of advertisements make reference to Joe Biden's America overlaid with images of current images, despite Trump being the current president[^5]. 

## Incumbency in Models So Far
All of this begs the question: how have I dealt with incumbency in the previous two posts? I took a similar approach in both, by estimating the incumbent and challenger vote shares seperately. One thing to note is that I have primiarily been working with incumbent *parties*, rather than incumbent candidates. Incumbent party presidents have only won 11 of the 18 electoions since World War II, and eight of the 11 wins were by incumbent presidents. This relationship is well documented in the Time for Change Model[^6].


If we take it as given that incumbency has some effect, it means that combinded with only using linear regressions, this left the impact of incumbency as an ommitted variable. Therefore the impact  was either absorbed by the coefficients on the predictors or by the error term. There is evidence in both directions. Becuase I looked at state level data for real disposable income, it may be that similar to [Kriner and Reeves (2012)](https://www-cambridge-org.ezp-prod1.hul.harvard.edu/core/services/aop-cambridge-core/content/view/D7E15E901EA52BF92E5986626766224F/S0003055412000159a.pdf/div-class-title-the-influence-of-federal-spending-on-presidential-elections-div.pdf), incumbency is tied to the real dispsoable income levels. However, I believe it is more likely it was absorbed into the error, which may be problematic from an endogeneity perspective[^7].

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
</script>

## Logistic Regression
One obvious critique of my models thus far has been that they are linear regressions to predict vote shares, which does not quite reflect the reality of voting. Many of the premeir election forecasters use probibalistic models, that instead simulate something like

$$Pr(VoteShare = 200000|VoterTurnout = 5000000) = f(\beta_0+\beta_1x_1 + \beta_2 x_2+...)$$
In practice, it means we want to estimate the probability of someone winning an election, or state, rather than just the vote share. A simple way of doing so is using a logistic regression. Instead of using vote share to estimate the outcomes, we use an indicator on who won the election. The predictions from the regression are then probabilities of results. A probability of greater than 50 percent can be thought of as someone winning a particular election. 

For this particular model, I used a tweaked version of the state level "polls plus" model from [last post](polls.html). There are five inputs: indicators for state and period[^8], along with state polling data, second quarter national GDP data, and second quarter state real disposable income. For this model, I used a logistic regression on indicator variables for if the incumbent party candidate won the election. 

```{css, echo=FALSE}
.scroll-100 {
  max-height: 250px;
  overflow-y: auto;
  background-color: inherit;
}
```

```{r polls_inc,echo=FALSE,  warning = FALSE, message = FALSE, class.output="scroll-100" }
summary(inc_log)
```

Interpreting the coefficients of the a logistic regression is a little different than with a linear regression. For the logistic regression, the coefficients are the change in [log odds](https://en.wikipedia.org/wiki/Logit). We can see that the coefficents on polling and GDP are both statistically significant. Assessing the fit of a logistic regression is a bit tricky, so one ad hoc way to do it is to see how many times the model is correct with leave one out validation. The logistic model performs quite well: the model predicts the correct outcome `r round(100*log_w, digits = 2)` percent of the time.

```{r pred, echo = FALSE, return = FALSE, warning = FALSE, message = FALSE}
## 2020 predictions
poll_2020_df <- read_csv("../Data/presidential_poll_averages_2020.csv")
elec_col <- read_csv("../Data/ElectoralCollegePost1948_adj.csv") %>% filter(Year> 1968)

elxnday_2020 <- as.Date("11/3/2020", "%m/%d/%Y")
dnc_2020 <- as.Date("8/20/2020", "%m/%d/%Y")
rnc_2020 <- as.Date("8/27/2020", "%m/%d/%Y")

colnames(poll_2020_df) <- c("year","state","poll_date","candidate_name","avg_support","avg_support_adj")

poll_2020_df <- poll_2020_df %>%
  mutate(party = case_when(candidate_name == "Donald Trump" ~ "republican",
                           candidate_name == "Joseph R. Biden Jr." ~ "democrat"),
         poll_date = as.Date(poll_date, "%m/%d/%Y")) %>%
  mutate(days_left = round(difftime(elxnday_2020, poll_date, unit="days")),
         weeks_left = round(difftime(elxnday_2020, poll_date, unit="weeks")),
         before_convention = case_when(poll_date < dnc_2020 & party == "democrat" ~ TRUE,
                                       poll_date < rnc_2020 & party == "republican" ~ TRUE,
                                       TRUE ~ FALSE)) %>% filter(!is.na(party)) 

poll_2020_clean <- poll_2020_df %>% filter(weeks_left < 25, weeks_left >=weeks) %>% 
  group_by(state, candidate_name, party) %>%
  summarize(avg_poll = mean(avg_support)) %>% filter(state != "National") %>% 
  select(state, candidate_name, avg_poll, party) %>% mutate(period = "1996-2020") %>%
  mutate(incumbent_party = case_when(candidate_name == "Joseph R. Biden Jr." ~ FALSE, 
                                     candidate_name == "Donald Trump" ~ TRUE)) %>%
  filter(state != "NE-1", state != "NE-2", state != "ME-1", state != "ME-2")

gdp <- rep(-0.0949, 102)
poll_2020_clean$gdp <- gdp
poll_2020_clean$avg_poll <- as.numeric(poll_2020_clean$avg_poll)

pred_data_df <- poll_2020_clean %>% left_join(state_rdi[,c(1,290)], c("state" = "State"))
colnames(pred_data_df) <- c("state", "candidate_name","avg_poll","party", "period", "incumbent_party","gdp", "rdi_q2")

pred_plus_inc <- predict(inc_plus_lm, pred_data_df %>% filter(incumbent_party == TRUE))
pred_log_inc <- 100*predict(inc_log, pred_data_df %>% filter(incumbent_party == TRUE), type = "response")
pred_ens_inc <- plus_w/(plus_w+log_w)*pred_plus_inc + log_w/(plus_w+log_w)*pred_log_inc

pred_df <- cbind.data.frame(unique(pred_data_df$state), pred_plus_inc, pred_log_inc, 
                            pred_ens_inc)

pred_win <- cbind.data.frame(unique(pred_data_df$state), 
                             case_when(pred_df$pred_plus_inc > 50 ~ "Trump",
                                       pred_df$pred_plus_inc < 50 ~ "Biden"),
                             case_when(pred_df$pred_log_inc > 50 ~ "Trump",
                                       pred_df$pred_log_inc < 50 ~ "Biden"),
                             case_when(pred_df$pred_ens_inc > 50 ~ "Trump",
                                       pred_df$pred_ens_inc < 50 ~ "Biden"))

colnames(pred_win) <- c("State", "polls plus", "logit", "ensemble")
pred_win_ec <- pred_win %>% left_join(elec_col %>% filter(Year==2020), by = ("State"="State"))
colnames(pred_win_ec) <- c("state", "polls", "logit", "ensemble","year","EC")
pred_win_ec <- remove_empty(pred_win_ec, which = c("cols"), quiet = TRUE)

plus_ec <- aggregate(pred_win_ec$EC, by=list(pred_win_ec$polls), FUN=sum)
logit_ec <- aggregate(pred_win_ec$EC, by=list(pred_win_ec$logit), FUN=sum)
ens_ec <- aggregate(pred_win_ec$EC, by=list(pred_win_ec$ensemble), FUN=sum)
```

We can also look at the predicted electoral map for 2020 using this regression. The predicted map is strange, thinking about intuitions on which states are likely to vote for Trump or Biden. 

```{r plusmap, echo=FALSE, warning = FALSE, results = FALSE}
plot_usmap(data = pred_win_ec, regions = "states", values = "logit") +
  scale_fill_manual(values = c("blue", "red"), 
                    name = "Projected winner by logistic regression model") +
  theme_void() + 
  labs(title =  "Electoral Map Predicted by Logistic Regression Model") +
    theme(plot.title = element_text(face="bold"))
```

This model predicts a Biden landslide, with Biden winning `r logit_ec[1,2]`  electoral college votes and Trump winning the remaining `r logit_ec[2,2]`. We can also look at the predicted probabilities of Trump winning each state. 

```{r prob, echo=FALSE,  warning = FALSE, results = 'asis', message = FALSE, class.output = "scroll-100", max.height='250px'}
  library(data.table)
  library(knitr)
  library(kableExtra)
  out <- cbind.data.frame(unique(pred_data_df$state),pred_log_inc)
  colnames(out) <- c("State","Predicted Probability of Trump Winning")
  out <- remove_empty(out, which = c("cols"), quiet = TRUE)
  kbl(out)  %>% kable_paper(full_width = F) %>%
  scroll_box(width = "500px", height = "200px") %>% kable_styling(position = "center")
```

## Reflections
Looking at this version of a probibalistic model, there appear to be similar problems to the linear regressions from last week. In general, it seems that there is too much weight given to the economy this year. This suggests that I should spend some time with ensemble models, looking at tuning the hyperparameters. However, given that for the most part, these models are fairly good at predicting past elections in leave one out validation, it may be that I have to experiment with ad hoc weighting. 

In addition, it may be that I need to move away from linear models. The underlying assumption of all of the models I have used so far is that the relationship between polling, the economy, and the various indicators is linear. One possible way to change the models is to experiment with interaction terms. Another method, that I think may be more promising, is to look at some sort of Bayesian updating model. Using a fundamentals model as a prior, and then updating with polling and information on shocks could be a much more effective way to predict elections.




[^1]: Many news outlets have shown that Trump's campaigning [never really stopped](https://www.npr.org/2019/06/18/733505037/trump-set-to-officially-launch-reelection-but-hasnt-he-been-running-all-along).

[^2]: There has been evidence that despite abysmal GDP and jobs numbers, the CARES Act was able to cause incomes to [increase during the second quarter of 2020](http://www.crfb.org/blogs/income-has-risen-through-covid-recession-may-soon-change). 

[^3]: This relationship makes me wonder by the Senate Republicans have not been willing to pass further stimulus, given that it would greatly help their re-election campaigns. 

[^4]: [This article from the Washington Post](https://projects.fivethirtyeight.com/coronavirus-polls/) gives a wonderful overview. 

[^5]: While [this piece from the New Yorker](https://www.newyorker.com/humor/daily-shouts/joe-bidens-america) is satire, it makes the point well. 

[^6]: [Abramowitz (2016)](https://centerforpolitics.org/crystalball/articles/forecasting-the-2016-presidential-election-will-time-for-change-mean-time-for-trump/)

[^7]: Correlation between the error term and the outcome variable is known as [endogeneity](https://en.wikipedia.org/wiki/Endogeneity_(econometrics)). Many econometric methods  have been developed to deal with this issue for causal inference. Up to this point, becuase I have focused on prediction, these methods have not been strictly neccesary, though I may explore them in the future. 
